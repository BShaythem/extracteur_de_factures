{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34153f00",
   "metadata": {},
   "source": [
    "# Donut Model Training for Invoice Extraction (Colab Version)\n",
    "\n",
    "This notebook is optimized for Google Colab with T4/P100 GPU (16GB VRAM).\n",
    "\n",
    "## Setup Steps:\n",
    "1. Upload your invoice dataset to Google Drive\n",
    "2. Mount your Drive\n",
    "3. Install dependencies\n",
    "4. Train the model\n",
    "\n",
    "Expected folder structure in Drive:\n",
    "```\n",
    "MyDrive/\n",
    "  data/\n",
    "    invoices-donut/\n",
    "      train/\n",
    "      valid/\n",
    "      donut_json/\n",
    "        train/\n",
    "        valid/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc48ea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU type and enable memory efficient settings\n",
    "!nvidia-smi\n",
    "\n",
    "# Install required packages\n",
    "!pip install transformers==4.31.0 datasets torch torchvision seqeval accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e96c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658623fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and GPU Setup\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "import json\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    DonutProcessor, \n",
    "    VisionEncoderDecoderModel,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    Trainer\n",
    ")\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import gc  # For memory management\n",
    "\n",
    "# Verify GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "print(f\"Using device: {device}\")\n",
    "if device == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc12a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading Function with memory optimization\n",
    "def load_split(split='train', chunk_size=100):\n",
    "    # Update these paths to match your Drive structure\n",
    "    image_dir = f'/content/drive/MyDrive/data/invoices-donut/{split}'\n",
    "    json_dir = f'/content/drive/MyDrive/data/invoices-donut/donut_json/{split}'\n",
    "    \n",
    "    # Create directories if they don't exist\n",
    "    os.makedirs(image_dir, exist_ok=True)\n",
    "    os.makedirs(json_dir, exist_ok=True)\n",
    "    \n",
    "    # Get all image files\n",
    "    image_files = sorted([f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    total_files = len(image_files)\n",
    "    data = []\n",
    "    \n",
    "    # Process in chunks to save memory\n",
    "    for i in range(0, total_files, chunk_size):\n",
    "        chunk = image_files[i:i + chunk_size]\n",
    "        print(f'Processing chunk {i//chunk_size + 1}/{(total_files + chunk_size - 1)//chunk_size}')\n",
    "    \n",
    "    for img_file in tqdm(chunk, desc=f'Loading chunk for {split}'):\n",
    "            img_path = os.path.join(image_dir, img_file)\n",
    "            json_path = os.path.join(json_dir, os.path.splitext(img_file)[0] + '.json')\n",
    "            if os.path.exists(json_path):\n",
    "                try:\n",
    "                    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "                        label = json.load(f)\n",
    "                        if 'raw_response' in label:\n",
    "                            label = json.loads(label['raw_response'])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {img_file}: {str(e)}\")\n",
    "                    continue\n",
    "                \n",
    "                # Free up memory by explicitly deleting unused variables\n",
    "                flat_label = {}\n",
    "                for k, v in label.items():\n",
    "                    if isinstance(v, (dict, list)):\n",
    "                        flat_label[k] = json.dumps(v, ensure_ascii=False)\n",
    "                    else:\n",
    "                        flat_label[k] = str(v)\n",
    "                data.append({'image_path': img_path, **flat_label})\n",
    "                del label, flat_label\n",
    "                \n",
    "                # Free memory after each chunk\n",
    "                if len(data) > chunk_size * 2:\n",
    "                    gc.collect()\n",
    "            \n",
    "    return data\n",
    "\n",
    "# Load datasets with chunking to save memory\n",
    "print(\"Loading training data...\")\n",
    "train_data = load_split('train', chunk_size=50)  # Smaller chunks to manage memory\n",
    "gc.collect()  # Clear memory after training data\n",
    "\n",
    "print(\"\\nLoading validation data...\")\n",
    "val_data = load_split('valid', chunk_size=50)\n",
    "gc.collect()  # Clear memory after validation data\n",
    "\n",
    "print(f'\\nLoaded {len(train_data)} training and {len(val_data)} validation image-label pairs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6824d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and processor\n",
    "model_name = \"naver-clova-ix/donut-base\"\n",
    "processor = DonutProcessor.from_pretrained(model_name)\n",
    "model = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
    "\n",
    "# Move model to GPU\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a732d2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Preprocessing\n",
    "def preprocess(example, processor):\n",
    "    import json\n",
    "    from PIL import Image\n",
    "    \n",
    "    pixel_values = []\n",
    "    labels_list = []\n",
    "    target_sequences = []\n",
    "    \n",
    "    batch_size = len(example['image_path'])\n",
    "    label_keys = [k for k in example.keys() if k != 'image_path']\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        label_dict = {k: example[k][i] for k in label_keys}\n",
    "        # Resize image to 384x384 for memory efficiency\n",
    "        image = Image.open(example['image_path'][i]).convert('RGB').resize((384, 384))\n",
    "        pixel_values.append(processor(image, return_tensors='pt').pixel_values[0])\n",
    "        \n",
    "        task_prompt = \"<s_invoice>\"\n",
    "        label_str = json.dumps(label_dict, ensure_ascii=False)\n",
    "        target_sequence = f\"{task_prompt}{label_str}</s_invoice>\"\n",
    "        target_sequences.append(target_sequence)\n",
    "        \n",
    "        labels = processor.tokenizer(\n",
    "            target_sequence,\n",
    "            padding='max_length',\n",
    "            max_length=512,\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        ).input_ids[0]\n",
    "        labels_list.append(labels)\n",
    "    \n",
    "    return {\n",
    "        'pixel_values': pixel_values,\n",
    "        'labels': labels_list,\n",
    "        'target_sequence': target_sequences\n",
    "    }\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "val_dataset = Dataset.from_list(val_data)\n",
    "\n",
    "# Process datasets\n",
    "train_dataset = train_dataset.map(\n",
    "    preprocess,\n",
    "    remove_columns=train_dataset.column_names,\n",
    "    num_proc=1,  # Single process for stability\n",
    "    fn_kwargs={'processor': processor},\n",
    "    batched=True,\n",
    "    batch_size=4,\n",
    "    keep_in_memory=False\n",
    ")\n",
    "\n",
    "val_dataset = val_dataset.map(\n",
    "    preprocess,\n",
    "    remove_columns=val_dataset.column_names,\n",
    "    num_proc=1,\n",
    "    fn_kwargs={'processor': processor},\n",
    "    batched=True,\n",
    "    batch_size=4,\n",
    "    keep_in_memory=False\n",
    ")\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "})\n",
    "\n",
    "# Set format for PyTorch\n",
    "dataset.set_format(type='torch', columns=['pixel_values', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73f3e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics computation\n",
    "def compute_metrics(eval_pred):\n",
    "    # Extract predictions and references from eval_pred\n",
    "    predictions = eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "    \n",
    "    # Process predictions\n",
    "    decoded_preds = processor.tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, processor.tokenizer.pad_token_id)\n",
    "    decoded_labels = processor.tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Count exact matches\n",
    "    exact_matches = sum(1 for pred, label in zip(decoded_preds, decoded_labels) if pred.strip() == label.strip())\n",
    "    exact_match_accuracy = exact_matches / len(decoded_preds)\n",
    "    \n",
    "    return {\"exact_match_accuracy\": exact_match_accuracy}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab195310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "output_dir = '/content/drive/MyDrive/models/donut-finetuned-invoice'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=2,  # Increased for 16GB GPU\n",
    "    per_device_eval_batch_size=2,   # Increased for 16GB GPU\n",
    "    num_train_epochs=3,\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    logging_steps=10,\n",
    "    learning_rate=5e-5,\n",
    "    fp16=True,                      # Mixed precision\n",
    "    gradient_checkpointing=True,    # Memory efficiency\n",
    "    gradient_accumulation_steps=4,  # Effective batch size of 8\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='exact_match_accuracy',\n",
    "    warmup_ratio=0.1,\n",
    "    report_to='none',\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False}\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['validation'],\n",
    "    tokenizer=processor.tokenizer,\n",
    "    data_collator=default_data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b9c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "trainer.train()\n",
    "\n",
    "# Save final model\n",
    "trainer.save_model()\n",
    "processor.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13584351",
   "metadata": {},
   "source": [
    "## Training Complete!\n",
    "\n",
    "The trained model and processor are saved in your Google Drive at: `/content/drive/MyDrive/models/donut-finetuned-invoice`\n",
    "\n",
    "Key improvements over local training:\n",
    "- Uses 16GB GPU efficiently\n",
    "- Larger batch sizes\n",
    "- Mixed precision training\n",
    "- Gradient checkpointing for memory efficiency\n",
    "- Auto-saves to Google Drive\n",
    "\n",
    "Expected training time: ~2-3 hours"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
